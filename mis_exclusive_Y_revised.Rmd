---
title: "mis_exclusive_Y_revised"
output: html_document
date: '2022-07-23'
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r}
# Governing Equation: y_i = alpha + x_1 b_1 + x_2 b_2 + x_3 b_3 + x_4 b_4 + e_i
# note alpha is intercept
create.data <- function(alpha = 20, beta_1 = 1, beta_2 = 2, beta_3 = 3, beta_4 = 4, 
                        sigma2 = 1, n = 50, run = 1) {
  set.seed(seed = run)
  x_1 <- rnorm(n)
  x_2 <- rnorm(n)
  x_3 <- rnorm(n)
  x_4 <- rnorm(n)
  y <- beta_1 * x_1 + beta_2 * x_2 + beta_3 * x_3 + beta_4 * x_4 + alpha
  + rnorm(n, sd = sqrt(sigma2))
  cbind("Ozone" = y, "Wind"= x_1, "Temp" = x_2, "Month" = x_3, "Day" = x_4)
}

MCAR.make.missing <- function(data, p = 0.5){
  rx <- rbinom(nrow(data), 1, p)
  data[rx == 0, "Ozone"] <- NA
  data
}
```


```{r}
sim_dataset <- as.data.frame(create.data(n = 200))
# NOTE missingness here is under MCAR mechanism. Could look into MAR, MNAR for
# further investiagtions.
# Note p is probability to NOT be missing.
missingness_sim_dataset <- MCAR.make.missing(sim_dataset, p = 0.7)
missingness_sim_dataset
```
### Missing Imputation

```{r}

simulate_MI2 <- function(runs = 100) {
  res <- array(NA, dim = c(5, runs, 3))
  times <- array(NA, dim = c(100, 1, 1))
  dimnames(res) <- list(c("Intercept", "Wind", "Temp", "Month", "Day"),
                        as.character(1:runs), c("estimate", "2.5%", "97.5%"))
  for (run in 1:runs){
      # Note that time is only measured for the MI/imp steps 
      # (i.e. filtering, predicting)
    start_time <- Sys.time()
    imp_MI <- mice(missingness_sim_dataset, print = FALSE)
    fit <- with(imp_MI, lm(Ozone ~ Wind + Temp + Month + Day))
    end_time <- Sys.time()
    tab <- summary(pool(fit), "all", conf.int = TRUE)  
    res[1, run, ] <- as.numeric(tab[1, c("estimate", "2.5 %", "97.5 %")])  
    res[2, run, ] <- as.numeric(tab[2, c("estimate", "2.5 %", "97.5 %")])
    res[3, run, ] <- as.numeric(tab[3, c("estimate", "2.5 %", "97.5 %")])
    res[4, run, ] <- as.numeric(tab[4, c("estimate", "2.5 %", "97.5 %")])
    res[5, run, ] <- as.numeric(tab[5, c("estimate", "2.5 %", "97.5 %")])
    
    times[run, 1, 1] <- as.numeric(end_time - start_time)
  }
  list(res, times)
}

```

```{r}
# Run 100 iterations of multiple imputations and store
res_MI2 <- simulate_MI2(100)
```



```{r}
# Obtain confidence intervals & estimates for all coefficients, intercept.
apply(res_MI2[[1]], c(1, 3), mean, na.rm = TRUE)

```
```{r}
# Mean time for iterations of multiple imputation
times <- res_MI2[[2]]
mean(times)
```

###  Listwise Deletion

```{r}
simulate_LD <- function(runs = 100){
  res <- array(NA, dim = c(5, 1, 3))
  dimnames(res) <- list(c("Intercept", "Wind", "Temp", "Month", "Day"),
                        as.character(1), c("estimate", "2.5%", "97.5%"))
  times <- array(NA, dim = c(runs, 1, 1))
  # Note that time is only measured for the LD/imp steps (i.e. filtering, predicting)
  for (run in 1:runs){
    start_time <- Sys.time()
    filtered_sim_dataset <- missingness_sim_dataset %>% 
      select(Ozone, Wind, Temp, Month, Day) %>%
      filter(!is.na(Ozone))
    fit <- with(filtered_sim_dataset, lm(Ozone ~ Wind + Temp + Month + Day))
    end_time <- Sys.time()
    times[run, 1, 1] <- as.numeric(end_time - start_time)
    # loop over each variable. Note we do the imputation just ONCE b/c LD is 
    # deterministic.
    if (run == 1){
      for (var in 1:5){
        edges <- as.numeric((confint(fit)[var,]))
        mid <- as.numeric(fit$coefficients)[var]
        interval <- c(edges[1], mid, edges[2])
        res[var, 1, ] <- interval
      }
    }
  
  }
  list(res, times)
}

```

```{r}
result_LD <- simulate_LD()
```

```{r}
# Obtain confidence intervals & estimates for all coefficients, intercept.
apply(result_LD[[1]], c(1, 3), mean, na.rm = TRUE)

```
```{r}
# Mean time for 100 instances of LD
times_LD <- result_LD[[2]]
mean(times_LD)
```