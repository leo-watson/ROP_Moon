dimnames(res) <- list(c("five_imps", paste(m_value, "_imputations", sep = '')),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MNAR.create.data(run = run, n = n)
data <- MNAR.make.missing(data, prob_missing_higher)
res[1, run, ] <- MNAR.test.impute(data, m= 5)
res[2, run, ] <- MNAR.test.impute(data, m = m_value)
print(paste("run", run,  "completed"))
}
res
}
res <- simulate(100)
simulate <- function(runs = 10) {
n = 100
prob_missing_higher = 0.5
m_value = 0.5 * prob_missing_higher * n
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imps", paste(m_value, "_imputations", sep = '')),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MNAR.create.data(run = run, n = n)
data <- MNAR.make.missing(data, prob_missing_higher)
res[1, run, ] <- MNAR.test.impute(data, m= 5)
res[2, run, ] <- MNAR.test.impute(data, m = m_value)
print(paste("run", run,  "completed"))
}
res
}
res <- simulate(100)
# Obtain estimates for \Beta in regression model along with 95% CI for each of the given methods.
apply(res, c(1, 3), mean, na.rm = TRUE)
# Obtain performance measures
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
# Obtain performance measures
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
simulate <- function(runs = 10) {
n = 100
prob_missing_higher = 0.5
m_value = 0.5 * prob_missing_higher * n
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imps", paste(m_value, "_imputations", sep = '')),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MNAR.create.data(run = run, n = n)
data <- MNAR.make.missing(data, prob_missing_higher)
res[1, run, ] <- MNAR.test.impute(data, m= 5)
res[2, run, ] <- MNAR.test.impute(data, m = m_value)
print(paste("run", run,  "completed"))
}
res
}
res <- simulate(100)
# Obtain estimates for \Beta in regression model along with 95% CI for each of the given methods.
apply(res, c(1, 3), mean, na.rm = TRUE)
# Obtain performance measures
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
simulate <- function(runs = 10) {
n = 100
prob_missing_higher = 0.8
m_value = 0.5 * prob_missing_higher * n
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imps", paste(m_value, "_imputations", sep = '')),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MNAR.create.data(run = run, n = n)
data <- MNAR.make.missing(data, prob_missing_higher)
res[1, run, ] <- MNAR.test.impute(data, m= 5)
res[2, run, ] <- MNAR.test.impute(data, m = m_value)
print(paste("run", run,  "completed"))
}
res
}
res <- simulate(100)
# Obtain estimates for \Beta in regression model along with 95% CI for each of the given methods.
apply(res, c(1, 3), mean, na.rm = TRUE)
# Obtain performance measures
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
simulate <- function(runs = 10) {
n = 300
prob_missing_higher = 0.2
m_value = 0.5 * prob_missing_higher * n
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imps", paste(m_value, "_imputations", sep = '')),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MNAR.create.data(run = run, n = n)
data <- MNAR.make.missing(data, prob_missing_higher)
res[1, run, ] <- MNAR.test.impute(data, m= 5)
res[2, run, ] <- MNAR.test.impute(data, m = m_value)
print(paste("run", run,  "completed"))
}
res
}
res <- simulate(100)
# Obtain estimates for \Beta in regression model along with 95% CI for each of the given methods.
apply(res, c(1, 3), mean, na.rm = TRUE)
# Obtain performance measures
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
simulate <- function(runs = 10) {
n = 100
prob_missing_higher = 0.5
m_value = 0.5 * prob_missing_higher * n
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imps", paste(m_value, "_imputations", sep = '')),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MNAR.create.data(run = run, n = n)
data <- MNAR.make.missing(data, prob_missing_higher)
res[1, run, ] <- MNAR.test.impute(data, m= 5)
res[2, run, ] <- MNAR.test.impute(data, m = m_value)
print(paste("run", run,  "completed"))
}
res
}
res <- simulate(100)
# Obtain estimates for \Beta in regression model along with 95% CI for each of the given methods.
apply(res, c(1, 3), mean, na.rm = TRUE)
# Obtain performance measures
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
simulate <- function(runs = 10) {
n = 100
prob_missing_higher = 0.8
m_value = 0.5 * prob_missing_higher * n
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imps", paste(m_value, "_imputations", sep = '')),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MNAR.create.data(run = run, n = n)
data <- MNAR.make.missing(data, prob_missing_higher)
res[1, run, ] <- MNAR.test.impute(data, m= 5)
res[2, run, ] <- MNAR.test.impute(data, m = m_value)
print(paste("run", run,  "completed"))
}
res
}
res <- simulate(100)
# Obtain estimates for \Beta in regression model along with 95% CI for each of the given methods.
apply(res, c(1, 3), mean, na.rm = TRUE)
# Obtain performance measures
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(mice)
# Creates function that create a dataset with 50 observations for a MUTLIPLE linear regression model with a categorical variable.
MAR.create.data <- function(beta = 1, sigma2 = 1, n = 50,
run = 1, beta2 = 10, categorical_var = "gender" , category_one = "M", category_zero = "F") {
set.seed(seed = run)
x <- rnorm(n)
# p represents probability of being in some group (E.g. Male = 1 vs Female = 0)
z <- rbinom(n, 1, p = 0.5)
temp <- cbind(x = x, z = z)
# Note the beta2 term for categorical variable effect.
y <- beta * x + rnorm(n, sd = sqrt(sigma2)) + beta2 * z
z[z == 0] <- category_zero
z[z == 1] <- category_one
# cat_var = categorical_var
data <- cbind(x = x, y = y, categorical_var = z)
# colnames(data) <- c("x", "y", categorical_var)
# sort df by categorical variable.
df <- as.data.frame(data) %>%
arrange(categorical_var)
}
# Creates function that removes p_0 % of data from category zero, p_1 % of data from category_one. Note this is effectively MCAR within each group (definition of MAR).
MAR.make.missing <- function(data, p_0 = 0.3, p_1 = 0.7 ){
# don't generate nrow(data) times, generate count of category times.
counts <- count(data, categorical_var)
num_cat_zero <-counts[1,2]
num_cat_one <- counts[2,2]
r_zero <- rbinom(counts[1,2], 1, p_0)
r_one <- rbinom(counts[2,2], 1, p_1)
data[1:num_cat_zero,1][r_zero == 1] <- NA
data[(num_cat_zero +1):nrow(data), 1][r_one ==1] <- NA
data
}
# Function that calls mice (applying imputation) and applies Rubin's Rules, and creates 95% confidence intervals for parameter
MAR.test.impute <- function(data, m = 5, method = "norm", ... ,threshold =  1.0) {
# Convert numerical vars to doubles (from character).
data_num <- as.data.frame(apply(data[,c(1:2)], 2, as.numeric))
# create copy
data_num_complete <- data_num
# add the categorical var
data_num_complete$categorical_var <- data[,3]
imp <- mice(data_num_complete, method = method, m = m, print = FALSE, ...)
fit <- with(imp, lm(y ~ x + categorical_var))
tab <- summary(pool(fit), "all", conf.int = TRUE)
as.numeric(tab[2, c("estimate", "2.5 %", "97.5 %")])
}
data <- MAR.create.data(n =50) %>% MAR.make.missing()
data %>% MAR.test.impute()
# Must convert observation values to double from character in order for mice() to work. Add check # to MAR.test.impute() that converts first two columns (numerical vars) to double.
data <- MAR.create.data(n =50) %>% MAR.make.missing()
# Applying MAR.test.impute() manually for debugging purposes.
data_num <- as.data.frame(apply(data %>% select(x,y), 2, as.numeric))
data_num_complete <- data_num
data_num_complete$categorical_var <- (data$categorical_var)
imp <- mice(data_num_complete)
fit <- with(imp, lm(y ~ x))
tab <- summary(pool(fit), "all", conf.int = TRUE)
as.numeric(tab[2, c("estimate", "2.5 %", "97.5 %")])
# Gives us information regarding the logged event warning.
imp$loggedEvents
simulate <- function(runs = 10) {
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("norm.predict", "norm.nob"),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MAR.create.data(run = run)
data <- MAR.make.missing(data)
res[1, run, ] <- MAR.test.impute(data, method = "norm.predict",
m = 2)
res[2, run, ] <- MAR.test.impute(data, method = "norm.nob")
}
res
}
# warning = FALSE
# Run the simulation and store in res. Do 1000 reps
# Alter # of imputations (m value in mice())
res <- simulate(1000)
# warning = FALSE
# Run the simulation and store in res. Do 1000 reps
# Alter # of imputations (m value in mice())
res <- simulate(100)
apply(res, c(1, 3), mean, na.rm = TRUE)
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
# e.g. m = 2, m= 5 as extra columns,
# try different parameter values (not 0, 1 special cases)
# MNAR: can do by writing full liklihood given we know the missing data mechanism (true in sim but not in real world).
# Apply mice() to MNAR with varying strengths of dependence (), see how results perform.
# Creates function that create a dataset with 50 observations for a MUTLIPLE linear regression model with a categorical variable.
MAR.create.data <- function(beta = 1, sigma2 = 1, n = 50,
run = 1, beta2 = 10, categorical_var = "gender" , category_one = "M", category_zero = "F") {
set.seed(seed = run)
x <- rnorm(n)
# p represents probability of being in some group (E.g. Male = 1 vs Female = 0)
z <- rbinom(n, 1, p = 0.5)
temp <- cbind(x = x, z = z)
# Note the beta2 term for categorical variable effect.
y <- beta * x + rnorm(n, sd = sqrt(sigma2)) + beta2 * z
z[z == 0] <- category_zero
z[z == 1] <- category_one
# cat_var = categorical_var
data <- cbind(x = x, y = y, categorical_var = z)
# colnames(data) <- c("x", "y", categorical_var)
# sort df by categorical variable.
df <- as.data.frame(data) %>%
arrange(categorical_var)
}
# Creates function that removes p_0 % of data from category zero, p_1 % of data from category_one. Note this is effectively MCAR within each group (definition of MAR).
MAR.make.missing <- function(data, p_0 = 0.3, p_1 = 0.7 ){
# don't generate nrow(data) times, generate count of category times.
counts <- count(data, categorical_var)
num_cat_zero <-counts[1,2]
num_cat_one <- counts[2,2]
r_zero <- rbinom(counts[1,2], 1, p_0)
r_one <- rbinom(counts[2,2], 1, p_1)
data[1:num_cat_zero,1][r_zero == 1] <- NA
data[(num_cat_zero +1):nrow(data), 1][r_one ==1] <- NA
data
}
# Function that calls mice (applying imputation) and applies Rubin's Rules, and creates 95% confidence intervals for parameter
MAR.test.impute <- function(data, m = 5) {
# Convert numerical vars to doubles (from character).
data_num <- as.data.frame(apply(data[,c(1:2)], 2, as.numeric))
# create copy
data_num_complete <- data_num
# add the categorical var
data_num_complete$categorical_var <- data[,3]
imp <- mice(data_num_complete, m = m, print = FALSE)
fit <- with(imp, lm(y ~ x + categorical_var))
tab <- summary(pool(fit), "all", conf.int = TRUE)
as.numeric(tab[2, c("estimate", "2.5 %", "97.5 %")])
}
simulate <- function(runs = 10) {
n = 300
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("norm.predict", "norm.nob"),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MAR.create.data(run = run)
data <- MAR.make.missing(data)
res[1, run, ] <- MAR.test.impute(data, method = "norm.predict",
m = 2)
res[2, run, ] <- MAR.test.impute(data, method = "norm.nob")
}
res
}
# warning = FALSE
# Run the simulation and store in res. Do 1000 reps
# Alter # of imputations (m value in mice())
res <- simulate(100)
simulate <- function(runs = 10) {
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imputations", "fifty_imputations"),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MAR.create.data(run = run, n= 300)
data <- MAR.make.missing(data, p_0 = 0.5, p_1 = 0.5)
res[1, run, ] <- MAR.test.impute(data, m = 5)
res[2, run, ] <- MAR.test.impute(data, m = 50)
}
res
}
# warning = FALSE
# Run the simulation and store in res. Do 1000 reps
# Alter # of imputations (m value in mice())
res <- simulate(100)
apply(res, c(1, 3), mean, na.rm = TRUE)
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
# e.g. m = 2, m= 5 as extra columns,
# try different parameter values (not 0, 1 special cases)
# MNAR: can do by writing full liklihood given we know the missing data mechanism (true in sim but not in real world).
# Apply mice() to MNAR with varying strengths of dependence (), see how results perform.
simulate <- function(runs = 10) {
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imputations", "fifty_imputations"),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MAR.create.data(run = run, n= 300)
data <- MAR.make.missing(data, p_0 = 0.3, p_1 = 0.7)
res[1, run, ] <- MAR.test.impute(data, m = 5)
res[2, run, ] <- MAR.test.impute(data, m = 50)
}
res
}
# warning = FALSE
# Run the simulation and store in res. Do 1000 reps
# Alter # of imputations (m value in mice())
res <- simulate(100)
apply(res, c(1, 3), mean, na.rm = TRUE)
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
# e.g. m = 2, m= 5 as extra columns,
# try different parameter values (not 0, 1 special cases)
# MNAR: can do by writing full liklihood given we know the missing data mechanism (true in sim but not in real world).
# Apply mice() to MNAR with varying strengths of dependence (), see how results perform.
simulate <- function(runs = 10) {
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imputations", "fifty_imputations"),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MAR.create.data(run = run, n= 300)
data <- MAR.make.missing(data, p_0 = 0.5, p_1 = 0.5)
res[1, run, ] <- MAR.test.impute(data, m = 5)
res[2, run, ] <- MAR.test.impute(data, m = 50)
}
res
}
# warning = FALSE
# Run the simulation and store in res. Do 1000 reps
# Alter # of imputations (m value in mice())
res <- simulate(100)
apply(res, c(1, 3), mean, na.rm = TRUE)
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
# e.g. m = 2, m= 5 as extra columns,
# try different parameter values (not 0, 1 special cases)
# MNAR: can do by writing full liklihood given we know the missing data mechanism (true in sim but not in real world).
# Apply mice() to MNAR with varying strengths of dependence (), see how results perform.
MNAR.create.data <- function(beta = 1, sigma2 = 1, n = 50,
run = 1) {
set.seed(seed = run)
x <- rnorm(n)
y <- beta * x + rnorm(n, sd = sqrt(sigma2))
as.data.frame(cbind(x = x, y = y))
}
# Create missingness in x values greater than median with specified probability.
MNAR.make.missing <- function(data, prob_missing_higher = 0.2){
higher <- data$x[data$x > median(data$x)]
data$x[data$x > median(data$x)] = ifelse(sample(
c(T, F), length(data$x[data$x > median(data$x)]), replace=T, prob=c(prob_missing_higher, 1 - prob_missing_higher)),
NA,
data$x[data$x > median(data$x)])
data
}
MNAR.test.impute <- function(data, m = 5) {
imp <- mice(data, m = m, print = FALSE)
fit <- with(imp, lm(y ~ x))
tab <- summary(pool(fit), "all", conf.int = TRUE)
as.numeric(tab[2, c("estimate", "2.5 %", "97.5 %")])
}
simulate <- function(runs = 10) {
n = 300
prob_missing_higher = 0.5
m_value = 0.5 * prob_missing_higher * n
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imps", paste(m_value, "_imputations", sep = '')),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MNAR.create.data(run = run, n = n)
data <- MNAR.make.missing(data, prob_missing_higher)
res[1, run, ] <- MNAR.test.impute(data, m= 5)
res[2, run, ] <- MNAR.test.impute(data, m = m_value)
print(paste("run", run,  "completed"))
}
res
}
res <- simulate(100)
# Obtain estimates for \Beta in regression model along with 95% CI for each of the given methods.
apply(res, c(1, 3), mean, na.rm = TRUE)
# Obtain performance measures
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
simulate <- function(runs = 10) {
n = 300
prob_missing_higher = 0.8
m_value = 0.5 * prob_missing_higher * n
res <- array(NA, dim = c(2, runs, 3))
dimnames(res) <- list(c("five_imps", paste(m_value, "_imputations", sep = '')),
as.character(1:runs),
c("estimate", "2.5 %","97.5 %"))
for(run in 1:runs) {
data <- MNAR.create.data(run = run, n = n)
data <- MNAR.make.missing(data, prob_missing_higher)
res[1, run, ] <- MNAR.test.impute(data, m= 5)
res[2, run, ] <- MNAR.test.impute(data, m = m_value)
print(paste("run", run,  "completed"))
}
res
}
res <- simulate(100)
# Obtain estimates for \Beta in regression model along with 95% CI for each of the given methods.
apply(res, c(1, 3), mean, na.rm = TRUE)
# Obtain performance measures
true <- 1
RB <- rowMeans(res[,, "estimate"]) - true
PB <- 100 * abs((rowMeans(res[,, "estimate"]) - true)/ true)
CR <- rowMeans(res[,, "2.5 %"] < true & true < res[,, "97.5 %"])
AW <- rowMeans(res[,, "97.5 %"] - res[,, "2.5 %"])
RMSE <- sqrt(rowMeans((res[,, "estimate"] - true)^2))
data.frame(RB, PB, CR, AW, RMSE)
